{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haddendataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_min_uc = 15\n",
    "cur_val_num = 500\n",
    "cur_te_num =500\n",
    "cur_n_items_u = 15\n",
    "cur_n_items_p = 50\n",
    "dataset_index = 4\n",
    "randomseed_num = 1\n",
    "#cur_train_por = 7 \n",
    "#cur_val_por = 3\n",
    "#cur_test_por =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539995\n",
      "377922\n",
      "(377922, 2)\n"
     ]
    }
   ],
   "source": [
    "raw_data_total = pd.read_csv(os.path.join(DATA_DIR, 'data.csv'), header=0)\n",
    "print(raw_data_total.shape[0])\n",
    "raw_data = pd.DataFrame({'count' : raw_data_total.groupby( [ \"users\", \"products\"] ).size()}).reset_index()\n",
    "del raw_data['count']\n",
    "print(raw_data.shape[0])\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61192,)\n"
     ]
    }
   ],
   "source": [
    "a = raw_data_total.groupby(\"users\").size()\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52570,)\n"
     ]
    }
   ],
   "source": [
    "b = raw_data_total.groupby(\"products\").size()\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377922, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_count id 별로 그룹화, 그룹별 데이터 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "         #기존 data를 min_sc 해당되는 movield만 filtering       \n",
    "        itemcount = get_count(tp, 'products')\n",
    "        tp = tp[tp['products'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'users')\n",
    "        #기존 data를 min_uc이상 해당되는 userld만 filtering\n",
    "        tp = tp[tp['users'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'users'), get_count(tp, 'products') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 data, 뽑아낸 usercont, 뽑아낸 movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data, 5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparsity 구하기 raw_data의 열의 갯수(filtering 된 raw data 총 갯수) / userid 갯수 * products 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 300872 watching events from 12156 users and 47365 products (sparsity: 0.052%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d products (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users\n",
      "187     379\n",
      "58      285\n",
      "1459    262\n",
      "394     258\n",
      "181     244\n",
      "       ... \n",
      "1153     15\n",
      "6755     15\n",
      "6719     15\n",
      "6703     15\n",
      "1433     15\n",
      "Length: 2019, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_count(raw_data,'users').sort_values(ascending= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getportion(val, test):\n",
    "    total = user_activity.index.shape[0]\n",
    "    return round(((total-val-test)/total)*100), round((val/total)*100), round((test/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataindex(val,test):\n",
    "    trainP,valP,testP = getportion(val,test)\n",
    "    print(trainP, valP, testP)\n",
    "    totalP = trainP + valP+ testP\n",
    "    totalUser = user_activity.sort_values(ascending= False)\n",
    "    sortedIndexUser = totalUser.reset_index()\n",
    "    print(sortedIndexUser)\n",
    "    #sortedIndexUser = sortedIndexUser[10:]\n",
    "    print(sortedIndexUser)\n",
    "    sortedIndex = sortedIndexUser['users']\n",
    "    sortedIndex_tr = sortedIndex[(sortedIndex.index%totalP>=0) & (sortedIndex.index%totalP<trainP)]\n",
    "    sortedIndex_va = sortedIndex[(sortedIndex.index%totalP>=trainP) & (sortedIndex.index%totalP<(trainP+valP))]\n",
    "    sortedIndex_te = sortedIndex[(sortedIndex.index%totalP>=(trainP+valP)) & (sortedIndex.index%totalP<(trainP+valP+testP))]\n",
    "    sorteduid = pd.concat([sortedIndex_tr,sortedIndex_va,sortedIndex_te])\n",
    "    return sorteduid.tolist(), sortedIndex_tr.tolist(),sortedIndex_va.tolist(), sortedIndex_te.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataindex_p(trainP,valP,testP):\n",
    "    print(trainP, valP, testP)\n",
    "    totalP = trainP + valP+ testP\n",
    "    totalUser = user_activity.sort_values(ascending= False)\n",
    "    sortedIndexUser = totalUser.reset_index()\n",
    "    print(sortedIndexUser)\n",
    "    #sortedIndexUser = sortedIndexUser[10:]\n",
    "    print(sortedIndexUser)\n",
    "    sortedIndex = sortedIndexUser['users']\n",
    "    sortedIndex_tr = sortedIndex[(sortedIndex.index%totalP>=0) & (sortedIndex.index%totalP<trainP)]\n",
    "    sortedIndex_va = sortedIndex[(sortedIndex.index%totalP>=trainP) & (sortedIndex.index%totalP<(trainP+valP))]\n",
    "    sortedIndex_te = sortedIndex[(sortedIndex.index%totalP>=(trainP+valP)) & (sortedIndex.index%totalP<(trainP+valP+testP))]\n",
    "    sorteduid = pd.concat([sortedIndex_tr,sortedIndex_va,sortedIndex_te])\n",
    "    return sorteduid.tolist(), sortedIndex_tr.tolist(),sortedIndex_va.tolist(), sortedIndex_te.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataindex_order_p(trainP,valP,testP):\n",
    "    print(trainP, valP, testP)\n",
    "    totalP = trainP + valP+ testP\n",
    "    totalUser = user_activity.sort_values(ascending= False)\n",
    "    sortedIndexUser = totalUser.reset_index()\n",
    "    #sortedIndexUser = sortedIndexUser[10:]\n",
    "    print(sortedIndexUser)\n",
    "    sortedIndex = sortedIndexUser['users']\n",
    "    tr_index = round(sortedIndexUser.shape[0]*(trainP/totalP))\n",
    "    vr_index = round(tr_index +sortedIndexUser.shape[0]*(valP/totalP))\n",
    "    print(\"trindex \", tr_index)\n",
    "    print(\"vindex\",vr_index)\n",
    "    sortedIndex_tr = sortedIndex[:tr_index]\n",
    "    sortedIndex_va = sortedIndex[tr_index:vr_index]\n",
    "    sortedIndex_te = sortedIndex[vr_index:]\n",
    "    sorteduid = pd.concat([sortedIndex_tr,sortedIndex_va,sortedIndex_te])\n",
    "    return sorteduid.tolist(), sortedIndex_tr.tolist(),sortedIndex_va.tolist(), sortedIndex_te.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomgetDataindex(val,test):\n",
    "    trainP,valP,testP = getportion(val,test)\n",
    "    print(trainP, valP, testP)\n",
    "    totalP = trainP + valP+ testP\n",
    "    totalUser = user_activity.sort_values(ascending= False)\n",
    "    sortedIndexUser = totalUser.reset_index()\n",
    "    #sortedIndexUser = sortedIndexUser[10:]\n",
    "    sortedIndex = sortedIndexUser['users'].tolist()\n",
    "    train = list()\n",
    "    val = list()\n",
    "    test = list()\n",
    "    curarr = list()\n",
    "    unique = list()\n",
    "    for i in range(len(sortedIndex)):\n",
    "        curarr.append(sortedIndex[i])\n",
    "        if len(curarr) == totalP:\n",
    "            curval = random.sample(curarr,valP)\n",
    "            val += curval\n",
    "            for k in curval :\n",
    "                curarr.remove(k)\n",
    "            testval = random.sample(curarr,testP)\n",
    "            test += testval\n",
    "            for k in testval :\n",
    "                curarr.remove(k)\n",
    "            train += curarr\n",
    "            curarr.clear()\n",
    "    if len(curarr) !=0 :\n",
    "        train += curarr\n",
    "    unique = train + val + test\n",
    "    print(set(sortedIndex)-set(unique))\n",
    "    print(set(train).intersection(val))\n",
    "    print(set(train).intersection(test))\n",
    "    print(set(val).intersection(test))\n",
    "    return unique,train,val,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unique_uid, tr_users, vd_users, te_users = getDataindex_order_p(cur_train_por,cur_val_por,cur_test_por)\n",
    "print(unique_uid[0])\n",
    "print(tr_users[0])\n",
    "print(tr_users[-1])\n",
    "print(vd_users[0])\n",
    "print(vd_users[-1])\n",
    "print(te_users[0])\n",
    "print(te_users[-1])\n",
    "print(unique_uid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unique_uid, tr_users, vd_users, te_users = getDataindex_p(cur_train_por,cur_val_por,cur_test_por)\n",
    "print(len(unique_uid))\n",
    "print(len(tr_users))\n",
    "print(len(vd_users))\n",
    "print(len(te_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 25 25\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "2019\n",
      "1019\n",
      "500\n",
      "500\n",
      "58\n",
      "187\n",
      "608\n"
     ]
    }
   ],
   "source": [
    "unique_uid, tr_users, vd_users, te_users = RandomgetDataindex(cur_val_num,cur_te_num)\n",
    "print(len(unique_uid))\n",
    "print(len(tr_users))\n",
    "print(len(te_users))\n",
    "print(len(te_users))\n",
    "print(tr_users[0])\n",
    "print(vd_users[0])\n",
    "print(te_users[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1019,)\n",
      "(46982, 2)\n"
     ]
    }
   ],
   "source": [
    "train_plays = raw_data.loc[raw_data['users'].isin(tr_users)]\n",
    "print(pd.unique(train_plays['users']).shape)\n",
    "print(train_plays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1156,)\n"
     ]
    }
   ],
   "source": [
    "unique_sid = pd.unique(train_plays['products'])\n",
    "print(unique_sid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "set()\n",
      "500\n",
      "500\n",
      "2019\n",
      "set()\n",
      "500\n",
      "500\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_uid))\n",
    "vad_plays = raw_data.loc[raw_data['users'].isin(vd_users)]\n",
    "vad_before_set = set(pd.unique(vad_plays['users']))\n",
    "vad_plays = vad_plays.loc[vad_plays['products'].isin(unique_sid)]\n",
    "vad_set = set(pd.unique(vad_plays['users']))\n",
    "remove_vad_uidx = vad_before_set - vad_set\n",
    "print(remove_vad_uidx)\n",
    "print(len(vad_before_set))\n",
    "print(len(vad_set))\n",
    "for x in remove_vad_uidx:\n",
    "    if x in unique_uid:\n",
    "                unique_uid.remove(x)\n",
    "test_plays = raw_data.loc[raw_data['users'].isin(te_users)]\n",
    "test_before_set = set(pd.unique(test_plays['users']))\n",
    "test_plays = test_plays.loc[test_plays['products'].isin(unique_sid)]\n",
    "test_set = set(pd.unique(test_plays['users']))\n",
    "remove_test_uidx = test_before_set-test_set\n",
    "print(len(unique_uid))\n",
    "print(remove_test_uidx)\n",
    "for x in remove_test_uidx:\n",
    "    if x in unique_uid:\n",
    "                unique_uid.remove(x)\n",
    "print(len(test_before_set))\n",
    "print(len(test_set))\n",
    "print(len(unique_uid))\n",
    "before_uid = len(unique_uid)\n",
    "before_vd = pd.unique(vad_plays['users']).shape\n",
    "before_te = pd.unique(test_plays['users']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSparsity(data):\n",
    "    usercount = get_count(data,'users')\n",
    "    itemcount = get_count(data, 'products')\n",
    "    sparsity = 1. * data.shape[0] / (usercount.shape[0] * len(unique_sid))\n",
    "    print(\"After filtering, there are %d watching events from %d users and %d products (sparsity: %.3f%%)\" % \n",
    "      (data.shape[0], usercount.shape[0], len(unique_sid), sparsity * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 46982 watching events from 1019 users and 1156 products (sparsity: 3.988%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity(train_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 23159 watching events from 500 users and 1156 products (sparsity: 4.007%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 22963 watching events from 500 users and 1156 products (sparsity: 3.973%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity(test_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data,cur_num_items,test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('users')\n",
    "    tr_list, te_list = list(), list()\n",
    "    np.random.seed(12)\n",
    "\n",
    "    for i, (index, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "        if n_items_u >= cur_num_items:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else :\n",
    "            if index in unique_uid:\n",
    "                unique_uid.remove(index)\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_palys_list = vad_plays_tr['users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_palys_list_te = vad_plays_te['users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n"
     ]
    }
   ],
   "source": [
    "print(len(tr_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(vad_plays_tr['users']).shape)\n",
    "print(pd.unique(vad_plays_te['users']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(test_plays_tr['users']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(test_plays_te['users']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(before_uid - len(unique_uid))\n",
    "print(before_te[0] - pd.unique(test_plays_tr['users']).shape[0])\n",
    "print(before_vd[0]- pd.unique(vad_plays_tr['users']).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    unique_sid는 train_plays에서 뽑는 unique한 users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    unique_uid는 뒤섞인것 기준\n",
    "    show2id는 index와 value를 바꾼 dict (unique_sid에서 뽑은 것 mapping) -> products : index\n",
    "    profile2id는 index와 value를 바꾼 dict (전체 unique_uid에서 뽑은 것 mapping) -> users : index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    unique_sid는 unique_sid.txt로 기록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dir ='./module12'\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid_'+str(dataset_index)+'.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    split_train_test_proportion함수 data를 userId로 그룹화\n",
    "    tr_list, te_list은 userId로 그룹화 된 data를 test_prop 만큼 비율로 나누어서 저장 \n",
    "    te_list는 그룹화된 (int) data 갯수 * test_prop 개의 random한 index를 가지는 data 저장\n",
    "    tr_list는 나머지 그룹화된 data 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    numerize 함수 userId와 movieId를 index로 mapping 후 uid(users) sid(products)로 dataFrame생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['users']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['products']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train_'+str(dataset_index)+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSparsity_S(data):\n",
    "    usercount = get_count(data,'uid')\n",
    "    itemcount = get_count(data, 'sid')\n",
    "    sparsity = 1. * data.shape[0] / (usercount.shape[0] * len(unique_sid))\n",
    "    print(\"After filtering, there are %d watching events from %d users and %d products (sparsity: %.3f%%)\" % \n",
    "      (data.shape[0], usercount.shape[0], len(unique_sid), sparsity * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 46982 watching events from 1019 users and 1156 products (sparsity: 3.988%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity_S(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr_'+str(dataset_index)+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 18717 watching events from 500 users and 1156 products (sparsity: 3.238%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity_S(vad_data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te_'+str(dataset_index)+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 4442 watching events from 500 users and 1156 products (sparsity: 0.769%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity_S(vad_data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr_'+str(dataset_index)+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 18562 watching events from 500 users and 1156 products (sparsity: 3.211%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity_S(test_data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te_'+str(dataset_index)+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 4401 watching events from 500 users and 1156 products (sparsity: 0.761%)\n"
     ]
    }
   ],
   "source": [
    "getSparsity_S(test_data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
